# Logistic Map
The logistic map is a mathematical model used to describe how populations change over time in a constrained environment. It is particularly famous for demonstrating how simple rules can lead to complex and even chaotic behavior.

Populations size $x_{t}$ is is given as a fraction of the maximum population an environment can sustain, called “*fraction of carrying capacity*”. $R$ is the growth rate, which influences how quickly the population grows.
$$x_{n+1}​=Rx_n​(1−x_n​)$$
With different values of $R$ the model exhibits population stabilization at a certain size ($1<R<3$), or oscillations and cycles ($3<R<3.57$) and even unpredictable chaotic behavior ($3>3.57$), although the model is deterministically, that is every $x_{t}$ maps to one $x_{t+1}$. 

Stabilization reflects real-world scenarios where populations grow until they reach a sustainable level. Oscillations and cycles may represent predator-prey dynamics or seasonal population changes. The value or set of values a populations settles into it fluctuates between are called **attractors**, which represent the long-term behavior of the system. 

With high values of $R$ fluctuations become unpredictably chaotic after about 30 iterations. This illustrates how sensitive ecosystems can be to small changes in initial conditions $x_{n}$. It is an example of the **butterfly effect**, a metaphor how tiny things can change the world or how a butterfly flapping its wings can set off a tornado. The concept of trifles becoming earth-shattereing events was around for some time when Edward Lorenz (1917–2008) known as the founder of modern chaos theory, placed it onto a quantitative base.

 > You could not remove a single grain of sand from its place without thereby … changing something throughout all parts of the immeasurable whole.– Fichte, The Vocation of Man (1800)

Lorenz was a meteorologist and messing around with a computer model of weather patterns in 1961 he noticed that very small rounding errors in his simulation compounded to large long-run effects. The prevailing view at the time was that minor discrepancies in the initial conditions would result in comparable forecast trajectories. If Lorenz was right most weather predictions and for that matter any prediction was garbage, because even a model as simple as the logistic map formula is so “*sensitive to initial conditions*” that the smallest rounding error will eventually dominate the solution.

You can look for attractors with $R<3.57$ and different values of $x_t$, or discover the so called **deterministic chaos** with $R>3.57$. In the latter region tiny changes of the initial $x_t$ in the sixth decimal place generate wildly differing trajectories in later periods. Even though the trajectories are fully determined by the equation above, the sensitivity to initial conditions implies: no matter how accurate our measurements get, no matter how fast our computers become, we will never be able to predict the likelihood of weather or anything else beyond a modest time horizon.